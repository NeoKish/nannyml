{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Data drift"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d691246",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nannyml as nml\n",
    "import pandas as pd\n",
    "\n",
    "reference, analysis, analysis_gt = nml.load_synthetic_sample()\n",
    "metadata = nml.extract_metadata(data = reference, model_name='wfh_predictor')\n",
    "metadata.target_column_name = 'work_home_actual'\n",
    "reference.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34dea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize the object that will perform the Univariate Drift calculations\n",
    "# Let's use a chunk size of 5000 data points to create our drift statistics\n",
    "univariate_calculator = nml.UnivariateStatisticalDriftCalculator(model_metadata=metadata, chunk_size=5000)\n",
    "# NannyML compares drift versus the full reference dataset.\n",
    "univariate_calculator.fit(reference_data=reference)\n",
    "# let's see drift statistics for all available data\n",
    "data = pd.concat([reference, analysis])\n",
    "univariate_results = univariate_calculator.calculate(data=data)\n",
    "# let's view a small subset of our results:\n",
    "univariate_results.iloc[:5, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44977044",
   "metadata": {},
   "outputs": [],
   "source": [
    "univariate_results.iloc[-5:, :9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cc7e15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's initialize the plotting class:\n",
    "plots = nml.DriftPlots(model_metadata=univariate_calculator.model_metadata, chunker=univariate_calculator.chunker)\n",
    "# let's plot drift results for all model inputs\n",
    "for feature in metadata.features:\n",
    "    figure = plots.plot_univariate_statistical_drift(univariate_results, metric='statistic', feature_label=feature.label)\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36244424",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's plot distribution drift results for continuous model inputs\n",
    "for feature in metadata.continuous_features:\n",
    "    figure = plots.plot_continuous_feature_distribution_over_time(\n",
    "        data=pd.concat([reference, analysis], ignore_index=True),\n",
    "        drift_results=univariate_results,\n",
    "        feature_label=feature.label\n",
    "    )\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1110f7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's plot distribution drift results for categorical model inputs\n",
    "for feature in metadata.categorical_features:\n",
    "    figure = plots.plot_categorical_feature_distribution_over_time(\n",
    "        data=pd.concat([reference, analysis], ignore_index=True),\n",
    "        drift_results=univariate_results,\n",
    "        feature_label=feature.label\n",
    "    )\n",
    "    figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fbfd04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ranker = nml.Ranker.by('alert_count')\n",
    "ranked_features = ranker.rank(univariate_results, model_metadata=metadata, only_drifting = False)\n",
    "ranked_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8755cf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plots.plot_univariate_statistical_prediction_drift(univariate_results, metric='statistic')\n",
    "figure.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab93e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's initialize the object that will perform Data Reconstruction with PCA\n",
    "# Let's use a chunk size of 5000 data points to create our drift statistics\n",
    "rcerror_calculator = nml.DataReconstructionDriftCalculator(model_metadata=metadata, chunk_size=5000)\n",
    "# NannyML compares drift versus the full reference dataset.\n",
    "rcerror_calculator.fit(reference_data=reference)\n",
    "# let's see RC error statistics for all available data\n",
    "rcerror_results = rcerror_calculator.calculate(data=data)\n",
    "rcerror_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c3fcfa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "figure = plots.plot_data_reconstruction_drift(rcerror_results)\n",
    "figure.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
